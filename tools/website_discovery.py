"""
CÃ´ng cá»¥ phÃ¡t hiá»‡n vÃ  test trang web lá»‹ch Ã¢m
TÃ¬m kiáº¿m cÃ¡c trang web hoáº¡t Ä‘á»™ng vÃ  format URL Ä‘Ãºng
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import re
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WebsiteDiscovery:
    """CÃ´ng cá»¥ phÃ¡t hiá»‡n trang web lá»‹ch Ã¢m hoáº¡t Ä‘á»™ng"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        
        # Danh sÃ¡ch cÃ¡c trang web tiá»m nÄƒng
        self.potential_sites = [
            'lichviet.app',
            'lichvn.net', 
            'tuvi.vn',
            'lichvannien.net',
            'lichngaytot.com',
            'licham365.vn',
            'lichvannien365.com',
            'lich.com.vn',
            'lichamnguyet.net',
            'lichvansu.net',
            '24h.com.vn',
            'dantri.com.vn',
            'vietnamnet.vn',
            'vnexpress.net',
            'baomoi.com',
            'kenh14.vn',
            'cafef.vn',
            'tinhte.vn'
        ]
        
        # CÃ¡c pattern URL phá»• biáº¿n cho lá»‹ch Ã¢m
        self.url_patterns = [
            '/lich-am/{year}/{month}',
            '/lich-van-nien/{year}-{month:02d}',
            '/lich-van-nien/thang-{month}-{year}.html',
            '/lich/{year}/{month}',
            '/calendar/{year}/{month}',
            '/{year}/{month:02d}',
            '/lich-am/{year}/{month:02d}',
            '/lich-am-duong/{year}/{month}',
            '/lunar-calendar/{year}/{month}',
            '/lich/{year}-{month:02d}',
            '/van-nien/{year}/{month}'
        ]
        
        # Selector patterns Ä‘á»ƒ tÃ¬m calendar data
        self.calendar_selectors = [
            '.calendar',
            '.calendar-container',
            '.lich-container',
            '.month-calendar',
            '.date-picker',
            '.calendar-wrapper',
            'table.calendar',
            '.lunar-calendar',
            '.am-lich',
            '.lich-am',
            '[class*="calendar"]',
            '[class*="lich"]',
            'td[data-date]',
            '.day-cell',
            '.calendar-day'
        ]

    def test_site_homepage(self, domain: str) -> Dict:
        """Test trang chá»§ cá»§a website"""
        result = {
            'domain': domain,
            'status': 'error',
            'accessible': False,
            'has_calendar_links': False,
            'calendar_links': [],
            'title': '',
            'error': None
        }
        
        try:
            url = f"https://{domain}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                result['status'] = 'success'
                result['accessible'] = True
                
                soup = BeautifulSoup(response.content, 'html.parser')
                title_text = soup.title.string if soup.title and soup.title.string else 'No title'
                result['title'] = title_text.strip() if title_text else 'No title'
                
                # TÃ¬m links liÃªn quan Ä‘áº¿n lá»‹ch
                calendar_keywords = ['lich', 'calendar', 'am', 'duong', 'van-nien', 'lunar']
                links = soup.find_all('a', href=True)
                
                for link in links:
                    href_attr = link.get('href') if hasattr(link, 'get') else None
                    href = str(href_attr).lower() if href_attr else ''
                    text = link.get_text().lower()
                    
                    if any(keyword in href or keyword in text for keyword in calendar_keywords):
                        full_url = urljoin(url, str(href_attr))
                        result['calendar_links'].append({
                            'url': full_url,
                            'text': link.get_text().strip()
                        })
                
                result['has_calendar_links'] = len(result['calendar_links']) > 0
                
            else:
                result['status'] = f'status_{response.status_code}'
                
        except requests.exceptions.RequestException as e:
            result['error'] = str(e)
            logger.warning(f"Lá»—i káº¿t ná»‘i {domain}: {e}")
            
        return result

    def test_calendar_url(self, domain: str, pattern: str, year: int = 2025, month: int = 7) -> Dict:
        """Test má»™t URL pattern cá»¥ thá»ƒ"""
        result = {
            'domain': domain,
            'pattern': pattern,
            'url': '',
            'status': 'error',
            'has_calendar_data': False,
            'calendar_elements': 0,
            'content_length': 0,
            'title': '',
            'error': None
        }
        
        try:
            # Táº¡o URL tá»« pattern
            path = pattern.format(year=year, month=month)
            url = f"https://{domain}{path}"
            result['url'] = url
            
            response = self.session.get(url, timeout=10)
            result['content_length'] = len(response.content)
            
            if response.status_code == 200:
                result['status'] = 'success'
                
                soup = BeautifulSoup(response.content, 'html.parser')
                title_text = soup.title.string if soup.title and soup.title.string else 'No title'
                result['title'] = title_text.strip() if title_text else 'No title'
                
                # Kiá»ƒm tra cÃ³ calendar data khÃ´ng
                calendar_elements = 0
                for selector in self.calendar_selectors:
                    elements = soup.select(selector)
                    calendar_elements += len(elements)
                
                result['calendar_elements'] = calendar_elements
                result['has_calendar_data'] = calendar_elements > 0
                
                # TÃ¬m dá»¯ liá»‡u ngÃ y cá»¥ thá»ƒ
                date_patterns = [
                    r'\d{1,2}\/\d{1,2}\/\d{4}',  # dd/mm/yyyy
                    r'\d{4}-\d{1,2}-\d{1,2}',    # yyyy-mm-dd
                    r'ngÃ y \d{1,2}',              # ngÃ y dd
                    r'can.*chi',                  # can chi
                    r'giÃ¡p|áº¥t|bÃ­nh|Ä‘inh|máº­u|ká»·|canh|tÃ¢n|nhÃ¢m|quÃ½',  # can
                    r'tÃ½|sá»­u|dáº§n|mÃ£o|thÃ¬n|tá»µ|ngá»|mÃ¹i|thÃ¢n|dáº­u|tuáº¥t|há»£i'  # chi
                ]
                
                text_content = soup.get_text().lower()
                for pattern_regex in date_patterns:
                    if re.search(pattern_regex, text_content):
                        result['has_calendar_data'] = True
                        break
                        
            else:
                result['status'] = f'status_{response.status_code}'
                
        except requests.exceptions.RequestException as e:
            result['error'] = str(e)
            
        return result

    def discover_working_sites(self) -> Dict:
        """TÃ¬m kiáº¿m táº¥t cáº£ trang web hoáº¡t Ä‘á»™ng"""
        logger.info("ğŸ” Báº¯t Ä‘áº§u phÃ¡t hiá»‡n trang web hoáº¡t Ä‘á»™ng...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'sites_tested': len(self.potential_sites),
            'patterns_tested': len(self.url_patterns),
            'homepage_results': [],
            'calendar_results': [],
            'working_sites': [],
            'summary': {}
        }
        
        # Test trang chá»§
        logger.info("ğŸ“– Testing homepages...")
        for domain in self.potential_sites:
            logger.info(f"Testing {domain}...")
            result = self.test_site_homepage(domain)
            results['homepage_results'].append(result)
            time.sleep(1)  # Rate limiting
        
        # Test calendar URLs
        logger.info("ğŸ“… Testing calendar URLs...")
        for domain in self.potential_sites:
            for pattern in self.url_patterns:
                logger.info(f"Testing {domain} with pattern {pattern}...")
                result = self.test_calendar_url(domain, pattern)
                results['calendar_results'].append(result)
                time.sleep(0.5)  # Rate limiting
        
        # PhÃ¢n tÃ­ch káº¿t quáº£
        working_sites = []
        accessible_sites = [r for r in results['homepage_results'] if r['accessible']]
        calendar_sites = [r for r in results['calendar_results'] if r['has_calendar_data']]
        
        # Tá»•ng há»£p sites hoáº¡t Ä‘á»™ng
        for site in calendar_sites:
            domain = site['domain']
            
            # TÃ¬m thÃ´ng tin homepage tÆ°Æ¡ng á»©ng
            homepage_info = next((r for r in accessible_sites if r['domain'] == domain), None)
            
            working_site = {
                'domain': domain,
                'homepage_accessible': homepage_info is not None,
                'calendar_url': site['url'],
                'calendar_pattern': site['pattern'],
                'calendar_elements': site['calendar_elements'],
                'title': site['title'],
                'calendar_links': homepage_info['calendar_links'] if homepage_info else []
            }
            
            working_sites.append(working_site)
        
        results['working_sites'] = working_sites
        
        # Táº¡o summary
        results['summary'] = {
            'total_sites': len(self.potential_sites),
            'accessible_homepages': len(accessible_sites),
            'sites_with_calendar_data': len(calendar_sites),
            'working_sites': len(working_sites),
            'success_rate': f"{len(working_sites)/len(self.potential_sites)*100:.1f}%"
        }
        
        logger.info(f"âœ… HoÃ n thÃ nh! TÃ¬m tháº¥y {len(working_sites)} trang web hoáº¡t Ä‘á»™ng")
        return results

    def save_results(self, results: Dict, filename: Optional[str] = None):
        """LÆ°u káº¿t quáº£ phÃ¡t hiá»‡n"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"website_discovery_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o {filename}")

def main():
    """Cháº¡y website discovery"""
    discovery = WebsiteDiscovery()
    results = discovery.discover_working_sites()
    
    discovery.save_results(results)
    
    # In káº¿t quáº£ summary
    print("\n" + "="*50)
    print("ğŸ“Š Káº¾T QUáº¢ PHÃT HIá»†N WEBSITE")
    print("="*50)
    
    summary = results['summary']
    print(f"ğŸŒ Tá»•ng sá»‘ sites test: {summary['total_sites']}")
    print(f"âœ… Homepages accessible: {summary['accessible_homepages']}")
    print(f"ğŸ“… Sites cÃ³ calendar data: {summary['sites_with_calendar_data']}")
    print(f"ğŸ¯ Sites hoáº¡t Ä‘á»™ng tá»‘t: {summary['working_sites']}")
    print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {summary['success_rate']}")
    
    print("\nğŸ¯ DANH SÃCH SITES HOáº T Ä‘á»™ng:")
    print("-"*30)
    for site in results['working_sites']:
        print(f"â€¢ {site['domain']}")
        print(f"  ğŸ“ URL: {site['calendar_url']}")
        print(f"  ğŸ“Š Elements: {site['calendar_elements']}")
        print(f"  ğŸ“– Title: {site['title']}")
        print()

if __name__ == "__main__":
    main()
