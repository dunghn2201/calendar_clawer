"""
X·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu l·ªãch √¢m
Chu·∫©n h√≥a format, lo·∫°i b·ªè duplicate, validate d·ªØ li·ªáu
"""

import json
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import re
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LichDataProcessor:
    """Class x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu l·ªãch √¢m"""
    
    def __init__(self, input_file: Optional[str] = None):
        self.input_file = input_file
        self.df: Optional[pd.DataFrame] = None
        self.cleaned_data: List[Dict[str, Any]] = []
        
        if input_file and Path(input_file).exists():
            self.load_data()
    
    def load_data(self) -> None:
        """Load d·ªØ li·ªáu t·ª´ file JSON ho·∫∑c CSV"""
        try:
            if self.input_file.endswith('.json'):
                with open(self.input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.df = pd.DataFrame(data)
            elif self.input_file.endswith('.csv'):
                self.df = pd.read_csv(self.input_file)
            else:
                raise ValueError("Ch·ªâ h·ªó tr·ª£ file JSON v√† CSV")
            
            logger.info(f"ƒê√£ load {len(self.df)} records t·ª´ {self.input_file}")
            
        except Exception as e:
            logger.error(f"L·ªói load d·ªØ li·ªáu: {e}")
            self.df = pd.DataFrame()
    
    def clean_solar_date(self, date_str: str) -> Optional[str]:
        """Chu·∫©n h√≥a ng√†y d∆∞∆°ng l·ªãch v·ªÅ format YYYY-MM-DD"""
        if not date_str:
            return None
        
        try:
            # ƒê√£ ƒë√∫ng format
            if re.match(r'\d{4}-\d{2}-\d{2}', date_str):
                return date_str
            
            # Format DD/MM/YYYY
            if re.match(r'\d{1,2}/\d{1,2}/\d{4}', date_str):
                day, month, year = date_str.split('/')
                return f"{year}-{int(month):02d}-{int(day):02d}"
            
            # Format DD-MM-YYYY
            if re.match(r'\d{1,2}-\d{1,2}-\d{4}', date_str):
                day, month, year = date_str.split('-')
                return f"{year}-{int(month):02d}-{int(day):02d}"
            
            # Ch·ªâ c√≥ s·ªë ng√†y (c·∫ßn th√™m th√¥ng tin th√°ng/nƒÉm)
            if date_str.isdigit() and 1 <= int(date_str) <= 31:
                return None  # C·∫ßn context ƒë·ªÉ x·ª≠ l√Ω
            
        except Exception as e:
            logger.warning(f"Kh√¥ng th·ªÉ parse ng√†y: {date_str} - {e}")
        
        return None
    
    def clean_lunar_date(self, lunar_str: str) -> Optional[str]:
        """Chu·∫©n h√≥a ng√†y √¢m l·ªãch"""
        if not lunar_str:
            return None
        
        try:
            # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt
            cleaned = re.sub(r'[^\d/]', '', lunar_str)
            
            # Format DD/MM ho·∫∑c DD/MM/YYYY
            if re.match(r'\d{1,2}/\d{1,2}(/\d{4})?', cleaned):
                return cleaned
            
            # T√°ch s·ªë
            numbers = re.findall(r'\d+', lunar_str)
            if len(numbers) >= 2:
                day, month = numbers[0], numbers[1]
                if len(numbers) >= 3:
                    year = numbers[2]
                    return f"{int(day):02d}/{int(month):02d}/{year}"
                else:
                    return f"{int(day):02d}/{int(month):02d}"
            
        except Exception as e:
            logger.warning(f"Kh√¥ng th·ªÉ parse ng√†y √¢m: {lunar_str} - {e}")
        
        return lunar_str.strip() if lunar_str else None
    
    def clean_can_chi(self, can_chi_str: str) -> Optional[str]:
        """Chu·∫©n h√≥a can chi"""
        if not can_chi_str:
            return None
        
        # Danh s√°ch can chi h·ª£p l·ªá
        can = ['Gi√°p', '·∫§t', 'B√≠nh', 'ƒêinh', 'M·∫≠u', 'K·ª∑', 'Canh', 'T√¢n', 'Nh√¢m', 'Qu√Ω']
        chi = ['T√Ω', 'S·ª≠u', 'D·∫ßn', 'M√£o', 'Th√¨n', 'T·ªµ', 'Ng·ªç', 'M√πi', 'Th√¢n', 'D·∫≠u', 'Tu·∫•t', 'H·ª£i']
        
        cleaned = can_chi_str.strip()
        
        # Ki·ªÉm tra format h·ª£p l·ªá
        for c in can:
            for ch in chi:
                if f"{c} {ch}" in cleaned or f"{c}{ch}" in cleaned:
                    return f"{c} {ch}"
        
        return cleaned if cleaned else None
    
    def validate_date(self, solar_date: str) -> bool:
        """Validate ng√†y d∆∞∆°ng l·ªãch"""
        try:
            datetime.strptime(solar_date, "%Y-%m-%d")
            return True
        except:
            return False
    
    def clean_and_process(self) -> pd.DataFrame:
        """L√†m s·∫°ch v√† x·ª≠ l√Ω to√†n b·ªô d·ªØ li·ªáu"""
        if self.df is None or self.df.empty:
            logger.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω")
            return pd.DataFrame()
        
        logger.info("B·∫Øt ƒë·∫ßu l√†m s·∫°ch d·ªØ li·ªáu...")
        
        # Copy dataframe
        cleaned_df = self.df.copy()
        
        # L√†m s·∫°ch ng√†y d∆∞∆°ng l·ªãch
        cleaned_df['solar_date'] = cleaned_df['solar_date'].astype(str).apply(self.clean_solar_date)
        
        # Lo·∫°i b·ªè records kh√¥ng c√≥ ng√†y d∆∞∆°ng l·ªãch h·ª£p l·ªá
        cleaned_df = cleaned_df.dropna(subset=['solar_date'])
        cleaned_df = cleaned_df[cleaned_df['solar_date'].apply(self.validate_date)]
        
        # L√†m s·∫°ch ng√†y √¢m l·ªãch
        if 'lunar_date' in cleaned_df.columns:
            cleaned_df['lunar_date'] = cleaned_df['lunar_date'].astype(str).apply(self.clean_lunar_date)
        
        # L√†m s·∫°ch can chi
        if 'can_chi_day' in cleaned_df.columns:
            cleaned_df['can_chi_day'] = cleaned_df['can_chi_day'].astype(str).apply(self.clean_can_chi)
        
        # Lo·∫°i b·ªè duplicates (based on solar_date v√† source)
        before_dedup = len(cleaned_df)
        cleaned_df = cleaned_df.drop_duplicates(subset=['solar_date', 'source'], keep='first')
        after_dedup = len(cleaned_df)
        
        if before_dedup > after_dedup:
            logger.info(f"ƒê√£ lo·∫°i b·ªè {before_dedup - after_dedup} duplicates")
        
        # S·∫Øp x·∫øp theo ng√†y
        cleaned_df = cleaned_df.sort_values('solar_date')
        
        # Reset index
        cleaned_df = cleaned_df.reset_index(drop=True)
        
        # Th√™m metadata
        cleaned_df['processed_at'] = datetime.now().isoformat()
        
        logger.info(f"Ho√†n th√†nh l√†m s·∫°ch: {len(cleaned_df)} records h·ª£p l·ªá")
        
        self.df = cleaned_df
        return cleaned_df
    
    def get_statistics(self) -> Dict[str, Any]:
        """Th·ªëng k√™ d·ªØ li·ªáu"""
        if self.df is None or self.df.empty:
            return {}
        
        stats = {
            'total_records': len(self.df),
            'date_range': {
                'from': self.df['solar_date'].min(),
                'to': self.df['solar_date'].max()
            },
            'sources': self.df['source'].value_counts().to_dict() if 'source' in self.df.columns else {},
            'missing_data': {
                'lunar_date': self.df['lunar_date'].isna().sum() if 'lunar_date' in self.df.columns else 0,
                'can_chi_day': self.df['can_chi_day'].isna().sum() if 'can_chi_day' in self.df.columns else 0,
                'holiday': self.df['holiday'].isna().sum() if 'holiday' in self.df.columns else 0
            },
            'holidays_count': len(self.df[self.df['holiday'].notna()]) if 'holiday' in self.df.columns else 0
        }
        
        return stats
    
    def export_to_json(self, output_file: str) -> None:
        """Xu·∫•t d·ªØ li·ªáu ra JSON"""
        if self.df is None or self.df.empty:
            logger.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t")
            return
        
        # Chuy·ªÉn NaN th√†nh None
        data = self.df.where(pd.notna(self.df), None).to_dict('records')
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ƒê√£ xu·∫•t {len(data)} records ra {output_file}")
    
    def export_to_sqlite(self, db_path: str) -> None:
        """Xu·∫•t d·ªØ li·ªáu ra SQLite"""
        if self.df is None or self.df.empty:
            logger.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t")
            return
        
        conn = sqlite3.connect(db_path)
        
        # T·∫°o b·∫£ng v·ªõi indexes
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS lich_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                solar_date TEXT NOT NULL,
                lunar_date TEXT,
                can_chi_day TEXT,
                can_chi_month TEXT,
                can_chi_year TEXT,
                holiday TEXT,
                notes TEXT,
                source TEXT,
                crawled_at TEXT,
                processed_at TEXT,
                UNIQUE(solar_date, source)
            )
        ''')
        
        # T·∫°o indexes
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_solar_date ON lich_data(solar_date)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_source ON lich_data(source)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_holiday ON lich_data(holiday)')
        
        # Insert d·ªØ li·ªáu
        self.df.to_sql('lich_data', conn, if_exists='replace', index=False)
        
        conn.commit()
        conn.close()
        
        logger.info(f"ƒê√£ xu·∫•t {len(self.df)} records ra SQLite database: {db_path}")
    
    def export_to_csv(self, output_file: str) -> None:
        """Xu·∫•t d·ªØ li·ªáu ra CSV"""
        if self.df is None or self.df.empty:
            logger.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t")
            return
        
        self.df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logger.info(f"ƒê√£ xu·∫•t {len(self.df)} records ra {output_file}")

# Ch·∫°y th·ª≠ nghi·ªám
if __name__ == "__main__":
    # T·∫°o d·ªØ li·ªáu test
    test_data = [
        {
            "solar_date": "2024-01-01",
            "lunar_date": "20/11/2023",
            "can_chi_day": "Gi√°p Th√¨n",
            "holiday": "T·∫øt D∆∞∆°ng l·ªãch",
            "source": "test"
        },
        {
            "solar_date": "1/1/2024",  # Format kh√°c
            "lunar_date": "20-11",
            "can_chi_day": "Gi√°p Th√¨n",
            "holiday": "",
            "source": "test"
        }
    ]
    
    # L∆∞u test data
    with open('test_data.json', 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    # Test processor
    processor = LichDataProcessor('test_data.json')
    cleaned = processor.clean_and_process()
    
    print("üßπ Cleaned data:")
    print(cleaned)
    
    print("\nüìä Statistics:")
    stats = processor.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # Export c√°c format
    processor.export_to_json('cleaned_data.json')
    processor.export_to_sqlite('test_database.db')
    processor.export_to_csv('cleaned_data.csv')
    
    print("‚úÖ Export ho√†n th√†nh!")
